<!DOCTYPE html>
<html>
  <head>
    <title>JavaScript Audio Example--Firefox only</title>

	<meta http-equiv="content-type" content="text/html; charset=UTF-8" charset="utf-8">

    <style>
    #main {
      display: block;
      margin: 0px auto;
      text-align: center
    }
    #content {
      display: inline-block;
    }
    #frames {
      display: inline-block;
      max-width: 180px;
      vertical-align: top;
    }
    #startbuttons {
      display: block;
    }
    #stopbuttons {
      display: none;
    }
    #message {
      font-size: 24px;
      font-family: "Gentium Basic", serif;
    }
    h1 {
      font-size: 40px;
      font-family: "Gentium Basic", serif;
    }
    input {
      font-size: 28px;
      font-family: "Gentium Basic", serif;
    }
    p {
      color: green;
    }
    p.error {
      color: red;
    }
  </style>


	<script src= "../javascripts/jquery-1.10.2.js"></script>

  </head>

  <body>
    <input type="text" size="4" id="freq" value="21000"><label for="hz">Hz</label>  <!-- 20,000Hz-25,000Hz -->
    <button onclick="start()">play</button>
    <button onclick="stop()">stop</button>


    <div id="main">
    <h2><b>getUserMedia Test Page</b></h2>
<a href="http://mozilla.github.com/webrtc-landing">Main webrtc demo page</a><br>
Note: Audio will feedback unless you use a headset!<br><br>
    <div id="startbuttons">
      <input value="Video" onclick="startVideo();" type="button">
      <input value="Audio" onclick="startAudio();" type="button">
      <input value="Audio &amp; Video" onclick="startAudioVideo();" type="button">
      <input value="Picture" onclick="startPicture();" type="button">
    </div>
    <div id="images">
       <div id="content"></div>
       <div id="frames"></div>
    </div>
    <div id="message"></div>
    <div style="display: none;" id="stopbuttons">
      <input value="Stop" onclick="stopMedia();" type="button">
      <input value="Pause/Play" onclick="pauseMedia();" type="button">
      <input id="snapshot" value="Snapshot" onclick="startSnapshot();" type="button">
    </div>
  </div>
  
  <script type="text/javascript" id = 'custom'>

  function feedback(bool) {

  }

  </script>

  <script type="application/javascript">
  var video_status = false;
  var video = document.createElement("video");
  video.setAttribute("width", 640);
  video.setAttribute("height", 480);

  var snapshots = [];

  var audio_status = false;
  var audio = document.createElement("audio");
  audio.setAttribute("controls", true);

  var picture_status = false;
  var picture = document.createElement("img");

  var start = document.getElementById("startbuttons");
  var stop = document.getElementById("stopbuttons");

  console.log(stop);

  var message = document.getElementById("message");
  var content = document.getElementById("content");
  var frames = document.getElementById("frames");
  var snapshot = document.getElementById("snapshot");
  
  var saved_stream = null;
  var capturing = false;

  function startVideo() {
    video_status = true;
    startMedia({video:true});
  }

  function startAudioVideo() {
    video_status = true;
    audio_status = true;
    startMedia({video:true, audio:true});
  }

  function startAudio() {
    audio_status = true;
    startMedia({audio:true});

    feedback(true);

  }

  function startPicture() {
    picture_status = true;
    startMedia({picture:true});
  }

  function stopMedia() {
    if (video_status) {
      video.mozSrcObject.stop();
      video.mozSrcObject = null;
      content.removeChild(video);
      stopbuttons.removeChild(snapshot);
      snapshot.value = "Snapshot";
      frames.innerHTML = '';
      capturing = false;
      video_status = false;
    } else if (audio_status) {
      audio.mozSrcObject.stop();
      audio.mozSrcObject = null;
      content.removeChild(audio);
      audio_status = false;
    } else if (picture_status) {
      picture.mozSrcObject = null;
      content.removeChild(picture);
      picture_status = false;
    }
    saved_stream = null;  
      $(stop).css("display","none");
      $(start).css("display", "block");
  }

  function pauseMedia() {
    if (saved_stream) {
      if (video_status) {
        video.mozSrcObject = saved_stream;
        video.play();
      } else if (audio_status) {
        audio.mozSrcObject = saved_stream;
        audio.play();
      }
      saved_stream = null;
    } else {
      if (video_status) {
        video.pause();
        saved_stream = video.mozSrcObject;
        video.mozSrcObject = null;
      } else if (audio_status) {
        audio.pause();
        saved_stream = audio.mozSrcObject;
        audio.mozSrcObject = null;
      }
    }
  }

  function startMedia(param) {
      $(stop).css("display","block");
      $(start).css("display", "none");
    try {
      window.navigator.mozGetUserMedia(param, function(stream) {

      	console.log(stream);

        message.innerHTML = "<p>Success!</p>";

        if (video_status) {
          content.appendChild(video);
          video.mozSrcObject = stream;
          video.play();
          frames.innerHTML = '';
          stopbuttons.appendChild(snapshot);
        } else if (audio_status) {
          content.appendChild(audio);
          audio.mozSrcObject = stream;
          audio.play();

        } else if (picture_status) {
          content.appendChild(picture);
          picture.src = window.URL.createObjectURL(stream);
          picture.onload = function(e) {
            window.URL.revokeObjectURL(this.src);
          }
        }
      }, function(err) {
        message.innerHTML = "<p class='error'>" + err + "</p>";
        stopMedia();
      });
    } catch(e) {
      message.innerHTML = "<p class='error'>" + e + "</p>";
      stopMedia();
    }
  }

  function startSnapshot() {
    capturing = !capturing;
    if (capturing) {
      captureImage();
      snapshot.value = "Stop Snapshot";
    } else {
      snapshot.value = "Snapshot";
    }
  }

  function captureImage() {
    if (video_status && capturing) {
      //dump("Capturing len " + snapshots.length + "\n");
      var canvas = document.createElement('canvas');
      var ctx = canvas.getContext('2d');

      canvas.width  = video.videoWidth/4;
      canvas.height = video.videoHeight/4;
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      if (snapshots.unshift(canvas) > 4)
        snapshots.length = 4;
      frames.innerHTML = '';
      for(var i=0; i<snapshots.length; i++) {
        frames.appendChild(snapshots[i]);
      }

      setTimeout(captureImage, 2000);
    }
  }
</script>


    <script type="text/javascript">    

      function AudioDataDestination(sampleRate, readFn) {
        // Initialize the audio output.
        var audio = new Audio();
        audio.mozSetup(1, sampleRate);

        var currentWritePosition = 0;
        var prebufferSize = sampleRate / 2; // buffer 500ms
        var tail = null;

        // The function called with regular interval to populate 
        // the audio output buffer.
        setInterval(function() {
          var written;
          // Check if some data was not written in previous attempts.
          if(tail) {  
            written = audio.mozWriteAudio(tail);
            currentWritePosition += written;
            if(written < tail.length) {
              // Not all the data was written, saving the tail...
              tail = tail.subarray(written);
              return; // ... and exit the function.
            }
            tail = null;
          }

          // Check if we need add some data to the audio output.
          var currentPosition = audio.mozCurrentSampleOffset();
          var available = currentPosition + prebufferSize - currentWritePosition;
          if(available > 0) {
            // Request some sound data from the callback function.
            var soundData = new Float32Array(parseFloat(available));
            readFn(soundData);

            // Writing the data.
            written = audio.mozWriteAudio(soundData);
            if(written < soundData.length) {
              // Not all the data was written, saving the tail.
              tail = soundData.slice(written);
            }
            currentWritePosition += written;
          }
        }, 100);
      }

      // Control and generate the sound.

      var frequency = 0, currentSoundSample;
      var sampleRate = 44100;

      function requestSoundData(soundData) {
        if (!frequency) { 
          return; // no sound selected
        }

        var k = 2* Math.PI * frequency / sampleRate;
        for (var i=0, size=soundData.length; i<size; i++) {
          soundData[i] = Math.sin(k * currentSoundSample++);
        }        
      }

      var audioDestination = new AudioDataDestination(sampleRate, requestSoundData);

      function start() {
        currentSoundSample = 0;
        frequency = parseFloat(document.getElementById("freq").value);
      }

      function stop() {
        frequency = 0;
      }
  </script>




  </body>
</html>